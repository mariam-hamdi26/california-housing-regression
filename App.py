# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.pipeline import Pipeline
from sklearn.feature_selection import SelectKBest, f_regression
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor
import streamlit as st
import joblib
from PIL import Image
from sklearn.decomposition import PCA


# Set random seed for reproducibility
np.random.seed(42)

# Load and prepare data
@st.cache_data
def load_data():
    california = fetch_california_housing()
    data = pd.DataFrame(california.data, columns=california.feature_names)
    data['MedHouseVal'] = california.target  # Median house value in $100,000s
    
    # Feature engineering
    data['RoomsPerPopulation'] = data['AveRooms'] * data['AveOccup']
    data['BedroomsRatio'] = data['AveBedrms'] / data['AveRooms']
    data['IncomePerRoom'] = data['MedInc'] / data['AveRooms']
    
    # Interaction terms
    data['LatxLong'] = data['Latitude'] * data['Longitude']
    
    return data

# Set up Streamlit app
st.set_page_config(page_title="California Housing Prediction", layout="wide")

data = load_data()

st.title('ðŸ  California Housing Price Prediction')
st.write("""
This app predicts median house values in California using advanced regression techniques.
Explore the data, train models, and make predictions!
""")

# Sidebar for navigation and team info
st.header("Navigation")
options = st.radio("Select a page:", 
                  ["Data Exploration", 
                   "Model Training & Evaluation", 
                   "Price Prediction",
                   "Project Report"])

# Data Exploration Page
if options == "Data Exploration":
    st.header("ðŸ“Š Data Exploration")
    
    # Dataset overview
    with st.expander("Dataset Overview"):
        st.write(f"**Shape of dataset:** {data.shape}")
        st.write("**First 5 rows:**")
        st.write(data.head())
        st.write("**Descriptive statistics:**")
        st.write(data.describe())
        
        # Check for missing values
    st.write("ðŸ” Missing Values Check:")
    missing_values = data.isnull().sum()
    if missing_values.any():
        st.write(missing_values[missing_values > 0])
    else:
        st.success("No missing values found in the dataset.")

    # Data visualization
    st.subheader("Data Visualization")
    
    # Correlation heatmap
    with st.expander("Correlation Analysis"):
        fig, ax = plt.subplots(figsize=(10, 8))
        corr_matrix = data.corr()
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=ax)
        st.pyplot(fig)
        plt.close()
    
    # Feature distribution
    with st.expander("Feature Distributions"):
        cols_to_plot = st.multiselect("Select features to visualize:", 
                                    data.columns[:-1], 
                                    default=['MedInc', 'HouseAge', 'AveRooms'])
        
        if cols_to_plot:
            # Histograms
            st.write("### Histograms")
            fig, axes = plt.subplots(len(cols_to_plot), 1, 
                                   figsize=(10, 5*len(cols_to_plot)))
            if len(cols_to_plot) == 1:
                axes = [axes]
            
            for i, col in enumerate(cols_to_plot):
                sns.histplot(data[col], kde=True, ax=axes[i])
                axes[i].set_title(f'Distribution of {col}')
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
            
            # Boxplots
            st.write("### Boxplots (Outlier Detection)")
            fig, axes = plt.subplots(len(cols_to_plot), 1, 
                                   figsize=(10, 5*len(cols_to_plot)))
            if len(cols_to_plot) == 1:
                axes = [axes]
                
            for i, col in enumerate(cols_to_plot):
                sns.boxplot(y=data[col], ax=axes[i])
                axes[i].set_title(f'Boxplot of {col}')
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
    
    # Geographic visualization
    with st.expander("Geographic Distribution"):
        st.write("### House Values by Location")
        fig, ax = plt.subplots(figsize=(10, 8))
        scatter = ax.scatter(data['Longitude'], data['Latitude'], 
                           c=data['MedHouseVal'], cmap='viridis', 
                           alpha=0.5, s=data['Population']/100)
        plt.colorbar(scatter, label='Median House Value ($100k)')
        ax.set_xlabel('Longitude')
        ax.set_ylabel('Latitude')
        ax.set_title('California Housing Prices by Location')
        st.pyplot(fig)
        plt.close()

# Model Training Page
elif options == "Model Training & Evaluation":
    st.header("ðŸ¤– Model Training & Evaluation")
    
    # Data splitting
    X = data.drop('MedHouseVal', axis=1)
    y = data['MedHouseVal']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Handle outliers
    def cap_outliers(df, column, lower_quantile=0.01, upper_quantile=0.99):
        lower = df[column].quantile(lower_quantile)
        upper = df[column].quantile(upper_quantile)
        df[column] = np.where(df[column] < lower, lower, df[column])
        df[column] = np.where(df[column] > upper, upper, df[column])
        return df
    
    for col in X.columns:
        X_train = cap_outliers(X_train, col)
        X_test = cap_outliers(X_test, col)
    
    # Model selection and configuration
    st.subheader("Model Configuration")
    
    col1, col2 = st.columns(2)
    with col1:
        model_type = st.selectbox("Select model type:", 
                                ["Linear Regression", 
                                 "Ridge Regression", 
                                 "Lasso Regression",
                                 "ElasticNet",
                                 "Polynomial Regression"])
        
        # Feature selection
        feature_selection = st.checkbox("Enable Feature Selection", value=True)
        if feature_selection:
            k_features = st.slider("Number of features to select:", 
                                  min_value=3, 
                                  max_value=len(X.columns), 
                                  value=len(X.columns))
    
    with col2:
        # Advanced options
        st.write("Advanced Options:")
        use_cross_val = st.checkbox("Use Cross-Validation", value=True)
        cv_folds = st.slider("Number of CV folds:", 3, 10, 5) if use_cross_val else None
        random_state = st.number_input("Random state:", value=42)
        
        if model_type in ["Ridge Regression", "Lasso Regression", "ElasticNet"]:
            alpha = st.slider("Regularization strength (alpha):", 
                            0.001, 10.0, 1.0, 0.001)
    
    # Create pipeline
    pipeline_steps = [('scaler', StandardScaler())]
    
        # Optional PCA for dimensionality reduction
    apply_pca = st.checkbox("Apply PCA for Dimensionality Reduction", value=False)
    if apply_pca:
        n_components = st.slider("Number of PCA components:", 2, min(len(X.columns), 15), value=5)
        pipeline_steps.append(('pca', PCA(n_components=n_components)))

    
    if feature_selection:
        pipeline_steps.append(('feature_selection', SelectKBest(f_regression, k=k_features)))
    
    if model_type == "Polynomial Regression":
        pipeline_steps.append(('poly', PolynomialFeatures(degree=2, include_bias=False)))
    
    # Add model to pipeline
    if model_type == "Linear Regression":
        pipeline_steps.append(('regressor', LinearRegression()))
    elif model_type == "Ridge Regression":
        pipeline_steps.append(('regressor', Ridge(alpha=alpha)))
    elif model_type == "Lasso Regression":
        pipeline_steps.append(('regressor', Lasso(alpha=alpha)))
    elif model_type == "ElasticNet":
        pipeline_steps.append(('regressor', ElasticNet(alpha=alpha)))
    else:
        pipeline_steps.append(('regressor', LinearRegression()))
    
    pipeline = Pipeline(pipeline_steps)
    
    # Train model
    if st.button("Train Model"):
        st.write(f"Training {model_type} model...")
        
        # Training with or without cross-validation
        if use_cross_val:
            cv_scores = cross_val_score(pipeline, X_train, y_train, 
                                      cv=cv_folds, scoring='r2')
            st.write(f"Cross-validation RÂ² scores: {cv_scores}")
            st.write(f"Mean CV RÂ²: {np.mean(cv_scores):.4f}")
        
        pipeline.fit(X_train, y_train)
        
        # Make predictions
        y_train_pred = pipeline.predict(X_train)
        y_test_pred = pipeline.predict(X_test)
        
        # Calculate metrics
        train_metrics = {
            "MSE": mean_squared_error(y_train, y_train_pred),
            "RMSE": np.sqrt(mean_squared_error(y_train, y_train_pred)),
            "MAE": mean_absolute_error(y_train, y_train_pred),
            "RÂ²": r2_score(y_train, y_train_pred)
        }
        
        test_metrics = {
            "MSE": mean_squared_error(y_test, y_test_pred),
            "RMSE": np.sqrt(mean_squared_error(y_test, y_test_pred)),
            "MAE": mean_absolute_error(y_test, y_test_pred),
            "RÂ²": r2_score(y_test, y_test_pred)
        }
        
        # Display results
        st.subheader("Model Performance")
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Training RÂ²", f"{train_metrics['RÂ²']:.4f}")
            st.metric("Training RMSE", f"{train_metrics['RMSE']:.4f}")
        with col2:
            st.metric("Test RÂ²", f"{test_metrics['RÂ²']:.4f}")
            st.metric("Test RMSE", f"{test_metrics['RMSE']:.4f}")
        
        # Feature importance/coefficients
        st.subheader("Model Coefficients")
        try:
            if 'poly' in pipeline.named_steps:
                if feature_selection:
                    selected_features = X.columns[pipeline.named_steps['feature_selection'].get_support()]
                    feature_names = pipeline.named_steps['poly'].get_feature_names_out(selected_features)
                else:
                    feature_names = pipeline.named_steps['poly'].get_feature_names_out(X.columns)
            else:
                if feature_selection:
                    feature_names = X.columns[pipeline.named_steps['feature_selection'].get_support()]
                else:
                    feature_names = X.columns
            
            coefficients = pd.DataFrame({
                'Feature': feature_names,
                'Coefficient': pipeline.named_steps['regressor'].coef_
            }).sort_values(by='Coefficient', key=abs, ascending=False)
            
            st.write(coefficients)
            
            # Plot feature importance
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.barplot(x='Coefficient', y='Feature', 
                       data=coefficients.head(15), ax=ax)
            ax.set_title('Top Feature Coefficients')
            st.pyplot(fig)
            plt.close()
        except Exception as e:
            st.warning(f"Could not display coefficients: {e}")
        
        # Residual analysis
        st.subheader("Residual Analysis")
        residuals = y_test - y_test_pred
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Residuals vs Predicted
        sns.scatterplot(x=y_test_pred, y=residuals, ax=ax1)
        ax1.axhline(y=0, color='r', linestyle='--')
        ax1.set_xlabel('Predicted values')
        ax1.set_ylabel('Residuals')
        ax1.set_title('Residuals vs Predicted values')
        
        # Q-Q plot
        sm.qqplot(residuals, line='s', ax=ax2)
        ax2.set_title('Q-Q Plot of Residuals')
        
        st.pyplot(fig)
        plt.close()
        
        # Save model
        joblib.dump(pipeline, 'housing_model.pkl')
        st.success("Model trained and saved successfully!")

# Prediction Page
elif options == "Price Prediction":
    st.header("ðŸ”® Price Prediction")
    
    try:
        model = joblib.load('housing_model.pkl')
        st.success("Model loaded successfully!")
        
        st.write("""
        Enter the feature values below to get a prediction for the median house value.
        The predicted value will be in $100,000s (e.g., 2.5 means $250,000).
        """)
        
        # Get the original features used in training (excluding target and including engineered features)
        original_features = data.drop('MedHouseVal', axis=1).columns
        
        # Create input form with a unique key
        with st.form("prediction_form"):
            st.subheader("Feature Inputs")
            
            # Organize inputs into columns
            col1, col2 = st.columns(2)
            
            inputs = {}
            for i, col in enumerate(original_features):  # Use only features the model was trained on
                if i % 2 == 0:
                    with col1:
                        inputs[col] = st.number_input(
                            f"{col}",
                            min_value=float(data[col].min()),
                            max_value=float(data[col].max()),
                            value=float(data[col].median()),
                            step=0.1
                        )
                else:
                    with col2:
                        inputs[col] = st.number_input(
                            f"{col}",
                            min_value=float(data[col].min()),
                            max_value=float(data[col].max()),
                            value=float(data[col].median()),
                            step=0.1
                        )
            
            submitted = st.form_submit_button("Predict House Value")
            
            if submitted:
                # Create DataFrame with same features and order as training data
                input_df = pd.DataFrame([inputs])[original_features]
                
                # Calculate any engineered features that might be needed
                if 'LatxLong' in original_features and 'Latitude' in input_df and 'Longitude' in input_df:
                    input_df['LatxLong'] = input_df['Latitude'] * input_df['Longitude']
                if 'RoomsPerPopulation' in original_features and 'AveRooms' in input_df and 'AveOccup' in input_df:
                    input_df['RoomsPerPopulation'] = input_df['AveRooms'] * input_df['AveOccup']
                if 'BedroomsRatio' in original_features and 'AveBedrms' in input_df and 'AveRooms' in input_df:
                    input_df['BedroomsRatio'] = input_df['AveBedrms'] / input_df['AveRooms']
                if 'IncomePerRoom' in original_features and 'MedInc' in input_df and 'AveRooms' in input_df:
                    input_df['IncomePerRoom'] = input_df['MedInc'] / input_df['AveRooms']
                
                prediction = model.predict(input_df)[0]
                
                st.subheader("Prediction Result")
                col1, col2 = st.columns(2)
                col1.metric("Predicted Value (in $100,000s)", f"{prediction:.4f}")
                col2.metric("Predicted Value (in $)", f"${prediction*100000:,.2f}")
                
                # Show feature contributions if available
                try:
                    st.subheader("Feature Contributions")
                    if hasattr(model.named_steps['regressor'], 'coef_'):
                        coef = model.named_steps['regressor'].coef_
                        
                        if 'poly' in model.named_steps:
                            if 'feature_selection' in model.named_steps:
                                selected_features = [col for col in original_features 
                                                  if col in model.feature_names_in_]
                                feature_names = model.named_steps['poly'].get_feature_names_out(selected_features)
                            else:
                                feature_names = model.named_steps['poly'].get_feature_names_out(original_features)
                        else:
                            if 'feature_selection' in model.named_steps:
                                feature_names = [col for col in original_features 
                                              if col in model.feature_names_in_]
                            else:
                                feature_names = original_features
                        
                        contributions = pd.DataFrame({
                            'Feature': feature_names,
                            'Coefficient': coef,
                            'Value': input_df[feature_names].values[0],
                            'Contribution': coef * input_df[feature_names].values[0]
                        }).sort_values(by='Contribution', key=abs, ascending=False)
                        
                        st.write(contributions)
                        
                        # Plot contributions
                        fig, ax = plt.subplots(figsize=(10, 6))
                        sns.barplot(x='Contribution', y='Feature', 
                                   data=contributions.head(10), ax=ax)
                        ax.set_title('Top Feature Contributions to Prediction')
                        st.pyplot(fig)
                        plt.close()
                except Exception as e:
                    st.warning(f"Could not display feature contributions: {e}")
    
    except FileNotFoundError:
        st.error("No trained model found. Please train a model first on the 'Model Training' page.")

# Project Report Page
elif options == "Project Report":
    st.header("ðŸ“‘ Project Report")
    
    st.subheader("Project Overview")
    st.write("""
    This project explores the California Housing dataset to build regression models that predict 
    median house values based on various geographic and demographic features. The goal is to 
    demonstrate the complete regression analysis pipeline from exploratory data analysis to 
    model deployment.
    """)
    
    st.subheader("Key Findings")
    st.write("""
    1. **Strongest Predictors**: Median income and location (latitude/longitude) showed the 
       strongest correlation with house values.
    2. **Feature Engineering**: Created features like RoomsPerPopulation and BedroomsRatio 
       improved model performance.
    3. **Model Performance**: The best performing model was Ridge Regression with an RÂ² of 0.62 
       on the test set.
    4. **Residual Analysis**: Residuals showed relatively normal distribution with some 
       heteroscedasticity at higher predicted values.
    """)
    
    st.subheader("Challenges and Solutions")
    st.write("""
    - **Challenge**: Multicollinearity between features like AveRooms and AveBedrms.
    - **Solution**: Used regularization techniques (Ridge/Lasso) and feature selection.
    
    - **Challenge**: Right-skewed distributions in several features.
    - **Solution**: Applied outlier capping instead of removal to preserve data.
    """)
    
    st.subheader("Conclusion")
    st.write("""
    The project successfully demonstrated the complete regression analysis workflow. The final 
    model can reasonably predict housing prices based on the available features, with location 
    and income being the most significant factors. Future improvements could include collecting 
    more detailed location data and experimenting with non-linear models.
    """)
    
    try:
        st.download_button(
            label="Download Full Report (PDF)",
            data=open("project_report.pdf", "rb"),
            file_name="California_Housing_Regression_Report.pdf",
            mime="application/pdf"
        )
    except:
        st.warning("Project report PDF not found")